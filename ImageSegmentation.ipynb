{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpnhuoljfIkL",
        "outputId": "b6f3671a-b2b3-455c-98bd-3a8b31743cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Conv2D, MaxPool2D, Input, concatenate, UpSampling2D, Dropout\n",
        "from keras.layers import Conv2DTranspose, AvgPool2D, GaussianNoise, BatchNormalization\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.metrics import MeanIoU\n",
        "import keras\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "\n",
        "\n",
        "def IoU(y_true, y_pred, eps=1e-6):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n",
        "    return -K.mean( (intersection) / (union + eps), axis=0)\n",
        "\n",
        "def get_model():\n",
        "    K.clear_session()\n",
        "    inputs = Input((256,256,3))\n",
        "    s = BatchNormalization()(inputs)\n",
        "    s = Dropout(0.5)(s)\n",
        "    \n",
        "    \n",
        "    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
        "    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
        "    p1 = MaxPool2D((2, 2)) (c1)\n",
        "    \n",
        "    \n",
        "    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
        "    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
        "    p2 = MaxPool2D((2, 2)) (c2)\n",
        "    \n",
        "    \n",
        "    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
        "    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
        "    p3 = MaxPool2D((2, 2)) (c3)\n",
        "    \n",
        "    \n",
        "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
        "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
        "    p4 = MaxPool2D(pool_size=(2, 2)) (c4)\n",
        "    \n",
        "    \n",
        "    c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
        "    c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
        "    \n",
        "    \n",
        "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
        "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
        "    \n",
        "    \n",
        "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
        "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
        "    \n",
        "    \n",
        "    \n",
        "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
        "    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
        "    \n",
        "    \n",
        "    \n",
        "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
        "    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
        "    \n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    print(model.summary())\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss=IoU, metrics=['binary_accuracy'])\n",
        "\n",
        "    return model\n",
        "    \n",
        "    \n",
        "X = np.load('/content/drive/My Drive/Data.ImageSegmentation/train_image.npy')\n",
        "Y = np.load('/content/drive/My Drive/Data.ImageSegmentation/mask_image.npy')\n",
        "\n",
        "def t_generator(X_train, Y_train, batch_size):\n",
        "    features = K.zeros(shape=(batch_size, 256,256,3))\n",
        "    labels = K.zeros(shape=(batch_size, 256,256,1))\n",
        "    while True:\n",
        "        start = 0\n",
        "        end = batch_size\n",
        "        for i in range(243):\n",
        "            features = X_train[start:end]\n",
        "            labels = Y_train[start:end]\n",
        "            start = end\n",
        "            end = end + batch_size\n",
        "            yield features / 255.0, labels / 255.0\n",
        "            \n",
        "            \n",
        "def v_generator(X_val, Y_val, batch_size):\n",
        "    features = K.zeros(shape=(batch_size, 256,256,3))\n",
        "    labels = K.zeros(shape=(batch_size, 256,256,1))\n",
        "    while True:\n",
        "        start = 0\n",
        "        end = batch_size\n",
        "        for i in range(27):\n",
        "            features = X_val[start:end]\n",
        "            labels = Y_val[start:end]\n",
        "            start = end\n",
        "            end = end + batch_size\n",
        "            yield features / 255.0, labels / 255.0\n",
        "            \n",
        "            \n",
        "        \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=265,\n",
        "                                                    test_size=0.1)\n",
        "\n",
        "del X, Y\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train,\n",
        "                                                  shuffle=True,\n",
        "                                                  random_state=265,\n",
        "                                                  test_size=0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model_chkpt = ModelCheckpoint('unet2_model_best.h5',\n",
        "                              monitor='binary_accuracy', verbose=1,\n",
        "                              save_best_only=True)\n",
        "\n",
        "\n",
        "history = model.fit(t_generator(X_train, Y_train, 32),\n",
        "                    steps_per_epoch=X_train.shape[0] // 32,\n",
        "                    epochs=500, callbacks=[model_chkpt],\n",
        "                    validation_data=v_generator(X_val, Y_val, 32),\n",
        "                    validation_steps=X_val.shape[0] // 32)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 3)  12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 256, 256, 3)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 8)  224         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 8)  584         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 8)  0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 16) 1168        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 16) 2320        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 32)   9248        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 64)   36928       conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 32, 32, 64)   32832       conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 128)  0           conv2d_transpose[0][0]           \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 64)   73792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 64)   36928       conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 32)   8224        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_1[0][0]         \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 32)   9248        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 16) 2064        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 128, 128, 32) 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 16) 2320        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 8)  520         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256, 256, 16) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 256, 256, 8)  1160        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 256, 256, 8)  584         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 1)  9           conv2d_17[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 485,829\n",
            "Trainable params: 485,823\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/500\n",
            "25/25 [==============================] - ETA: 0s - loss: -0.1235 - binary_accuracy: 0.8070\n",
            "Epoch 00001: binary_accuracy improved from -inf to 0.80698, saving model to unet2_model_best.h5\n",
            "25/25 [==============================] - 219s 9s/step - loss: -0.1235 - binary_accuracy: 0.8070 - val_loss: -0.1403 - val_binary_accuracy: 0.7123\n",
            "Epoch 2/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: nan - binary_accuracy: 0.8003\n",
            "Epoch 00002: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 9ms/step - loss: nan - binary_accuracy: 0.8003 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 3/500\n",
            "23/25 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00003: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 4/500\n",
            "23/25 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00004: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 5/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00005: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 6/500\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00006: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 7/500\n",
            "19/25 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00007: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 8/500\n",
            "23/25 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00008: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 9/500\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00009: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 10/500\n",
            "25/25 [==============================] - ETA: 0s - loss: nan - binary_accuracy: 0.7992\n",
            "Epoch 00010: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 65s 3s/step - loss: nan - binary_accuracy: 0.7992 - val_loss: nan - val_binary_accuracy: 0.8333\n",
            "Epoch 11/500\n",
            "19/25 [=====================>........] - ETA: 49s - loss: -0.1504 - binary_accuracy: 0.7721\n",
            "Epoch 00011: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 158s 6s/step - loss: nan - binary_accuracy: 0.7721 - val_loss: nan - val_binary_accuracy: 0.8169\n",
            "Epoch 12/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00012: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 13/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00013: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 14/500\n",
            "21/25 [========================>.....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00014: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 15/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00015: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 16/500\n",
            "21/25 [========================>.....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00016: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 17/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00017: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 18/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00018: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 19/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00019: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 3s 101ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: nan - val_binary_accuracy: 0.8333\n",
            "Epoch 20/500\n",
            "25/25 [==============================] - ETA: 0s - loss: nan - binary_accuracy: 0.2622\n",
            "Epoch 00020: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 126s 5s/step - loss: nan - binary_accuracy: 0.2622 - val_loss: nan - val_binary_accuracy: 0.8169\n",
            "Epoch 21/500\n",
            "24/25 [===========================>..] - ETA: 3s - loss: nan - binary_accuracy: 0.2302 \n",
            "Epoch 00021: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 94s 4s/step - loss: nan - binary_accuracy: 0.2302 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 22/500\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00022: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 23/500\n",
            "22/25 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00023: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 24/500\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00024: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 25/500\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00025: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 26/500\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00026: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 27/500\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00027: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 28/500\n",
            "23/25 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00028: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 3s 102ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: nan - val_binary_accuracy: 0.8333\n",
            "Epoch 29/500\n",
            "21/25 [========================>.....] - ETA: 0s - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00\n",
            "Epoch 00029: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 2s 87ms/step - loss: 0.0000e+00 - binary_accuracy: 0.0000e+00 - val_loss: nan - val_binary_accuracy: 0.8169\n",
            "Epoch 30/500\n",
            "25/25 [==============================] - ETA: 0s - loss: nan - binary_accuracy: 0.7049\n",
            "Epoch 00030: binary_accuracy did not improve from 0.80698\n",
            "25/25 [==============================] - 190s 8s/step - loss: nan - binary_accuracy: 0.7049 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00\n",
            "Epoch 31/500\n",
            " 3/25 [==>...........................] - ETA: 2:09 - loss: -0.3270 - binary_accuracy: 0.8039"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}