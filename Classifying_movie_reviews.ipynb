{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying movie reviews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRK8yWPJoWXm",
        "outputId": "ac433f29-1c7f-45da-db58-203dc5d589c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels)= imdb.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF3ziqY9oyRA",
        "outputId": "e86d21fe-a363-471b-e524-9e9141980c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjUxLL6so9Ut",
        "outputId": "ebf2f638-cff5-4c91-ce50-0ea35b41690a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xduNcJGMpDGq",
        "outputId": "dd847ecd-f63e-4f4f-9ede-3f0f85e3daa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de4aUTsmrXTO"
      },
      "source": [
        "word_index=imdb.get_word_index()\n",
        "reverse_word_index=dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "decoded_review=' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vETpp_0_rasQ",
        "outputId": "d14100d5-77c8-4a48-bc8f-14f49a9c5900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "decoded_review"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKSeK1OArhir"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorizee_sequences(sequences, dimension=10000):\n",
        "  results=np.zeros((len(sequences), dimension))\n",
        "  for i, sequences in enumerate(sequences):\n",
        "    results[i, sequences]=1.\n",
        "  return results\n",
        "\n",
        "x_train=vectorizee_sequences(train_data)\n",
        "x_test=vectorizee_sequences(test_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZl5G6eDuLfr",
        "outputId": "1c469014-3d36-44fd-d0b4-0d93d3809824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8oDdvukuSGK"
      },
      "source": [
        "y_train=np.asarray(train_labels).astype('float32')\n",
        "y_test=np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhuT3xPsv2DH"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLclfoUtwn1_"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofT6vcQIxPUG"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G2ogqO5x5dJ"
      },
      "source": [
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB1GOixiylvd"
      },
      "source": [
        "x_val=x_train[:10000]\n",
        "partial_x_train=x_train[10000:]\n",
        "\n",
        "y_val=y_train[:10000]\n",
        "partial_y_train=y_train[10000:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FkrzUsjzT0n",
        "outputId": "4f04b4fc-141c-4b31-a154-5e8e2931655b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "history=model.fit(partial_x_train,\n",
        "                  partial_y_train,\n",
        "                  epochs=20,\n",
        "                  batch_size=512,\n",
        "                  validation_data=(x_val, y_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.5102 - binary_accuracy: 0.7905 - val_loss: 0.3892 - val_binary_accuracy: 0.8713\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.3126 - binary_accuracy: 0.9029 - val_loss: 0.3084 - val_binary_accuracy: 0.8858\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2344 - binary_accuracy: 0.9219 - val_loss: 0.2791 - val_binary_accuracy: 0.8908\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1828 - binary_accuracy: 0.9427 - val_loss: 0.2785 - val_binary_accuracy: 0.8889\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.1498 - binary_accuracy: 0.9521 - val_loss: 0.2880 - val_binary_accuracy: 0.8847\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1256 - binary_accuracy: 0.9612 - val_loss: 0.2860 - val_binary_accuracy: 0.8872\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1051 - binary_accuracy: 0.9675 - val_loss: 0.3404 - val_binary_accuracy: 0.8743\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0879 - binary_accuracy: 0.9751 - val_loss: 0.3199 - val_binary_accuracy: 0.8831\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0728 - binary_accuracy: 0.9801 - val_loss: 0.3486 - val_binary_accuracy: 0.8814\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0609 - binary_accuracy: 0.9841 - val_loss: 0.3705 - val_binary_accuracy: 0.8761\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0533 - binary_accuracy: 0.9867 - val_loss: 0.3904 - val_binary_accuracy: 0.8770\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0401 - binary_accuracy: 0.9911 - val_loss: 0.4211 - val_binary_accuracy: 0.8754\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0332 - binary_accuracy: 0.9933 - val_loss: 0.4528 - val_binary_accuracy: 0.8746\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0272 - binary_accuracy: 0.9946 - val_loss: 0.4906 - val_binary_accuracy: 0.8717\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0201 - binary_accuracy: 0.9969 - val_loss: 0.5258 - val_binary_accuracy: 0.8704\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0168 - binary_accuracy: 0.9977 - val_loss: 0.5623 - val_binary_accuracy: 0.8667\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0143 - binary_accuracy: 0.9981 - val_loss: 0.6005 - val_binary_accuracy: 0.8657\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0084 - binary_accuracy: 0.9996 - val_loss: 0.6349 - val_binary_accuracy: 0.8666\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0101 - binary_accuracy: 0.9989 - val_loss: 0.6726 - val_binary_accuracy: 0.8663\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0049 - binary_accuracy: 0.9999 - val_loss: 0.8261 - val_binary_accuracy: 0.8494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vCgHWLOz2Og",
        "outputId": "f3baf5cd-27d5-4f7b-a34a-8edbd6cc3b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "history_dict=history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8hLEynB0FCw",
        "outputId": "3d5517cd-79f0-4772-f133-1b8265f54f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "results=model.evaluate(x_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 1s 11ms/step - loss: 0.4461 - accuracy: 0.8150\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 11ms/step - loss: 0.2538 - accuracy: 0.9098\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 11ms/step - loss: 0.1973 - accuracy: 0.9304\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 11ms/step - loss: 0.1668 - accuracy: 0.9412\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3035 - accuracy: 0.8810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLc79ole33T0",
        "outputId": "b264e136-7832-4206-c4e3-a068b6ccc7a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30350226163864136, 0.8809999823570251]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoUVRCwP37UN",
        "outputId": "a275c400-1c89-4260-df39-25ca43ad59db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16454558],\n",
              "       [0.99995947],\n",
              "       [0.79015964],\n",
              "       ...,\n",
              "       [0.09786242],\n",
              "       [0.05727214],\n",
              "       [0.5745712 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}